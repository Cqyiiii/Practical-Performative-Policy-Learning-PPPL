{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd318b8-c3f9-4315-9513-20c406ae593a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.455\n",
      "epoch: 1, loss: 1.216\n",
      "epoch: 2, loss: 1.554\n",
      "epoch: 3, loss: 1.334\n",
      "epoch: 4, loss: 1.084\n",
      "epoch: 5, loss: 1.164\n",
      "epoch: 6, loss: 1.292\n",
      "epoch: 7, loss: 1.273\n",
      "epoch: 8, loss: 1.208\n",
      "epoch: 9, loss: 1.114\n",
      "epoch: 10, loss: 1.108\n",
      "epoch: 11, loss: 1.297\n",
      "epoch: 12, loss: 1.269\n",
      "epoch: 13, loss: 1.075\n",
      "epoch: 14, loss: 1.181\n",
      "epoch: 15, loss: 1.209\n",
      "epoch: 16, loss: 1.282\n",
      "epoch: 17, loss: 1.222\n",
      "epoch: 18, loss: 1.207\n",
      "epoch: 19, loss: 1.104\n",
      "epoch: 20, loss: 1.134\n",
      "epoch: 21, loss: 1.209\n",
      "epoch: 22, loss: 1.199\n",
      "epoch: 23, loss: 1.211\n",
      "epoch: 24, loss: 1.244\n",
      "epoch: 25, loss: 1.243\n",
      "epoch: 26, loss: 1.354\n",
      "epoch: 27, loss: 1.201\n",
      "epoch: 28, loss: 1.271\n",
      "epoch: 29, loss: 1.203\n",
      "epoch: 30, loss: 1.180\n",
      "epoch: 31, loss: 1.234\n",
      "epoch: 32, loss: 1.204\n",
      "epoch: 33, loss: 1.159\n",
      "epoch: 34, loss: 1.192\n",
      "epoch: 35, loss: 1.078\n",
      "epoch: 36, loss: 1.336\n",
      "epoch: 37, loss: 1.146\n",
      "epoch: 38, loss: 1.125\n",
      "epoch: 39, loss: 0.965\n",
      "epoch: 40, loss: 1.153\n",
      "epoch: 41, loss: 1.161\n",
      "epoch: 42, loss: 1.160\n",
      "epoch: 43, loss: 1.281\n",
      "epoch: 44, loss: 1.190\n",
      "epoch: 45, loss: 1.088\n",
      "epoch: 46, loss: 1.037\n",
      "epoch: 47, loss: 1.202\n",
      "epoch: 48, loss: 1.176\n",
      "epoch: 49, loss: 1.094\n",
      "epoch: 50, loss: 1.015\n",
      "epoch: 51, loss: 1.170\n",
      "epoch: 52, loss: 1.203\n",
      "epoch: 53, loss: 1.143\n",
      "epoch: 54, loss: 1.065\n",
      "epoch: 55, loss: 1.180\n",
      "epoch: 56, loss: 1.036\n",
      "epoch: 57, loss: 1.020\n",
      "epoch: 58, loss: 1.192\n",
      "epoch: 59, loss: 1.112\n",
      "epoch: 60, loss: 1.124\n",
      "epoch: 61, loss: 1.098\n",
      "epoch: 62, loss: 1.093\n",
      "epoch: 63, loss: 1.092\n",
      "epoch: 64, loss: 1.150\n",
      "epoch: 65, loss: 1.215\n",
      "epoch: 66, loss: 1.010\n",
      "epoch: 67, loss: 1.125\n",
      "epoch: 68, loss: 1.102\n",
      "epoch: 69, loss: 1.089\n",
      "epoch: 70, loss: 1.201\n",
      "epoch: 71, loss: 1.186\n",
      "epoch: 72, loss: 1.101\n",
      "epoch: 73, loss: 1.101\n",
      "epoch: 74, loss: 1.095\n",
      "epoch: 75, loss: 1.133\n",
      "epoch: 76, loss: 1.189\n",
      "epoch: 77, loss: 1.113\n",
      "epoch: 78, loss: 1.138\n",
      "epoch: 79, loss: 1.143\n",
      "epoch: 80, loss: 1.128\n",
      "epoch: 81, loss: 1.113\n",
      "epoch: 82, loss: 1.130\n",
      "epoch: 83, loss: 1.101\n",
      "epoch: 84, loss: 1.141\n",
      "epoch: 85, loss: 1.116\n",
      "epoch: 86, loss: 1.069\n",
      "epoch: 87, loss: 1.056\n",
      "epoch: 88, loss: 1.015\n",
      "epoch: 89, loss: 1.112\n",
      "epoch: 90, loss: 1.165\n",
      "epoch: 91, loss: 1.180\n",
      "epoch: 92, loss: 1.253\n",
      "epoch: 93, loss: 1.220\n",
      "epoch: 94, loss: 1.187\n",
      "epoch: 95, loss: 1.228\n",
      "epoch: 96, loss: 1.087\n",
      "epoch: 97, loss: 1.120\n",
      "epoch: 98, loss: 1.114\n",
      "epoch: 99, loss: 1.061\n",
      "tensor([[[0.2410, 0.3521, 0.4069],\n",
      "         [0.4353, 0.2344, 0.3303],\n",
      "         [0.2383, 0.4787, 0.2829],\n",
      "         [0.2967, 0.3806, 0.3228],\n",
      "         [0.2929, 0.3480, 0.3591],\n",
      "         [0.1932, 0.4413, 0.3655],\n",
      "         [0.2313, 0.3860, 0.3827],\n",
      "         [0.1610, 0.5068, 0.3322],\n",
      "         [0.3586, 0.3598, 0.2817],\n",
      "         [0.2872, 0.2917, 0.4212]],\n",
      "\n",
      "        [[0.4443, 0.3267, 0.2290],\n",
      "         [0.4606, 0.2491, 0.2903],\n",
      "         [0.2337, 0.4102, 0.3561],\n",
      "         [0.2480, 0.4419, 0.3101],\n",
      "         [0.3600, 0.3277, 0.3123],\n",
      "         [0.2373, 0.4813, 0.2814],\n",
      "         [0.2182, 0.4489, 0.3329],\n",
      "         [0.2450, 0.4627, 0.2923],\n",
      "         [0.2030, 0.5366, 0.2604],\n",
      "         [0.3829, 0.3602, 0.2568]],\n",
      "\n",
      "        [[0.4127, 0.2245, 0.3628],\n",
      "         [0.2261, 0.3372, 0.4367],\n",
      "         [0.2599, 0.3497, 0.3904],\n",
      "         [0.1569, 0.3932, 0.4499],\n",
      "         [0.3163, 0.3174, 0.3663],\n",
      "         [0.2272, 0.3914, 0.3814],\n",
      "         [0.3942, 0.2003, 0.4055],\n",
      "         [0.2445, 0.3213, 0.4342],\n",
      "         [0.1612, 0.5497, 0.2892],\n",
      "         [0.3218, 0.3015, 0.3767]],\n",
      "\n",
      "        [[0.2198, 0.4565, 0.3237],\n",
      "         [0.5222, 0.2878, 0.1900],\n",
      "         [0.3273, 0.3656, 0.3071],\n",
      "         [0.2268, 0.4062, 0.3670],\n",
      "         [0.2747, 0.3835, 0.3418],\n",
      "         [0.2395, 0.3788, 0.3818],\n",
      "         [0.2481, 0.3955, 0.3564],\n",
      "         [0.3061, 0.3396, 0.3543],\n",
      "         [0.3271, 0.4771, 0.1958],\n",
      "         [0.2166, 0.4355, 0.3478]],\n",
      "\n",
      "        [[0.4044, 0.3362, 0.2593],\n",
      "         [0.2429, 0.3532, 0.4040],\n",
      "         [0.3262, 0.4034, 0.2704],\n",
      "         [0.3149, 0.3554, 0.3297],\n",
      "         [0.3859, 0.2994, 0.3148],\n",
      "         [0.2349, 0.3743, 0.3907],\n",
      "         [0.4124, 0.3215, 0.2660],\n",
      "         [0.2745, 0.4011, 0.3244],\n",
      "         [0.5008, 0.3523, 0.1469],\n",
      "         [0.3384, 0.4090, 0.2526]],\n",
      "\n",
      "        [[0.2065, 0.4296, 0.3639],\n",
      "         [0.2975, 0.2663, 0.4362],\n",
      "         [0.3329, 0.3288, 0.3382],\n",
      "         [0.2027, 0.3236, 0.4737],\n",
      "         [0.4158, 0.3073, 0.2769],\n",
      "         [0.2767, 0.3938, 0.3294],\n",
      "         [0.1981, 0.4735, 0.3284],\n",
      "         [0.1708, 0.3469, 0.4823],\n",
      "         [0.3865, 0.3860, 0.2275],\n",
      "         [0.3445, 0.3716, 0.2839]],\n",
      "\n",
      "        [[0.3856, 0.3199, 0.2945],\n",
      "         [0.4350, 0.2617, 0.3032],\n",
      "         [0.1710, 0.3716, 0.4575],\n",
      "         [0.3313, 0.3349, 0.3338],\n",
      "         [0.4627, 0.2775, 0.2598],\n",
      "         [0.2746, 0.4103, 0.3151],\n",
      "         [0.2226, 0.4790, 0.2984],\n",
      "         [0.2221, 0.4805, 0.2974],\n",
      "         [0.2805, 0.3138, 0.4058],\n",
      "         [0.2927, 0.3391, 0.3683]],\n",
      "\n",
      "        [[0.3730, 0.3698, 0.2572],\n",
      "         [0.1431, 0.4343, 0.4226],\n",
      "         [0.3241, 0.2799, 0.3960],\n",
      "         [0.2037, 0.4168, 0.3795],\n",
      "         [0.2415, 0.4143, 0.3442],\n",
      "         [0.1529, 0.4554, 0.3916],\n",
      "         [0.1652, 0.3584, 0.4763],\n",
      "         [0.2472, 0.3308, 0.4220],\n",
      "         [0.3337, 0.2011, 0.4653],\n",
      "         [0.5185, 0.1977, 0.2838]],\n",
      "\n",
      "        [[0.3749, 0.2403, 0.3848],\n",
      "         [0.4003, 0.2381, 0.3616],\n",
      "         [0.2952, 0.3481, 0.3567],\n",
      "         [0.3686, 0.3443, 0.2872],\n",
      "         [0.3716, 0.2114, 0.4170],\n",
      "         [0.2156, 0.3498, 0.4346],\n",
      "         [0.2237, 0.2701, 0.5062],\n",
      "         [0.2953, 0.2858, 0.4190],\n",
      "         [0.2456, 0.4364, 0.3180],\n",
      "         [0.3262, 0.3193, 0.3545]],\n",
      "\n",
      "        [[0.2890, 0.3203, 0.3907],\n",
      "         [0.1797, 0.4985, 0.3218],\n",
      "         [0.3952, 0.3009, 0.3040],\n",
      "         [0.2172, 0.4420, 0.3409],\n",
      "         [0.4451, 0.3227, 0.2322],\n",
      "         [0.2628, 0.4091, 0.3281],\n",
      "         [0.5965, 0.1959, 0.2076],\n",
      "         [0.4394, 0.2515, 0.3091],\n",
      "         [0.3559, 0.3416, 0.3025],\n",
      "         [0.2300, 0.5858, 0.1842]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.likelihoods import SoftmaxLikelihood\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Generate some sample data\n",
    "num_data = 100\n",
    "num_features = 5\n",
    "num_classes = 3\n",
    "X_train = torch.randn(num_data, num_features)\n",
    "y_train = torch.randint(0, num_classes, (num_data,))\n",
    "\n",
    "# Define a multi-output GP model for multiclass classification\n",
    "class MulticlassGPModel(ApproximateGP):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        variational_distribution = CholeskyVariationalDistribution(num_inducing_points=50)\n",
    "        variational_strategy = VariationalStrategy(self, torch.randn(50, num_features), variational_distribution, learn_inducing_locations=True)\n",
    "        super(MulticlassGPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([num_classes]))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(batch_shape=torch.Size([num_classes])), batch_shape=torch.Size([num_classes]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Instantiate the model and likelihood\n",
    "model = MulticlassGPModel(num_features=num_features, num_classes=num_classes)\n",
    "likelihood = SoftmaxLikelihood(num_classes=num_classes, mixing_weights=None)\n",
    "\n",
    "# Define the marginal log likelihood (MLL) objective\n",
    "mll = VariationalELBO(likelihood, model, num_data=X_train.size(0))\n",
    "\n",
    "# Setup training\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': likelihood.parameters()}], lr=0.01)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "for epoch in range(100):\n",
    "    \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        loss = -mll(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch: {}, loss: {:.3f}\".format(epoch, loss.item()))\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Predict on new data\n",
    "# with torch.no_grad(), gpytorch.settings.num_likelihood_samples(10):\n",
    "test_x = torch.randn(10, num_features)  # example test data\n",
    "preds = likelihood(model(test_x))\n",
    "\n",
    "# Extract predicted probabilities that support backpropagation\n",
    "predicted_probabilities = preds.probs\n",
    "print(predicted_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0191805c-f1b6-4cb7-b356-31d17dd773bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m       \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m            _lazy_property_and_property\n",
       "\u001b[0;31mString form:\u001b[0m     <torch.distributions.utils._lazy_property_and_property object at 0x7fe3ef552a40>\n",
       "\u001b[0;31mFile:\u001b[0m            ~/miniconda3/envs/myconda/lib/python3.10/site-packages/torch/distributions/utils.py\n",
       "\u001b[0;31mDocstring:\u001b[0m       <no docstring>\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "We want lazy properties to look like multiple things.\n",
       "\n",
       "* property when Sphinx autodoc looks\n",
       "* lazy_property when Distribution validate_args looks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4a533c-fdc1-4daf-9b82-0748a11e84e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_probabilities = preds.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835abc20-8446-4454-b244-09d16e396b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec96592-7238-4cc1-8ec3-e1b995e051dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.enable_grad(), gpytorch.settings.num_likelihood_samples(10):\n",
    "    test_x = torch.randn(10, num_features)  # example test data\n",
    "    preds = likelihood(model(test_x))\n",
    "predicted_probabilities = preds.probs\n",
    "predicted_probabilities.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5e57220-d30d-4a95-bc3b-13039ca1ccaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c01ec19-69d7-4ffe-8869-d2399f06cf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4aa64ab-e50f-4240-887a-c150baf955a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2735, 0.3779, 0.3485],\n",
       "        [0.3033, 0.4045, 0.2922],\n",
       "        [0.2721, 0.3386, 0.3893],\n",
       "        [0.2908, 0.3926, 0.3166],\n",
       "        [0.3435, 0.3606, 0.2959],\n",
       "        [0.2832, 0.3628, 0.3540],\n",
       "        [0.3078, 0.3588, 0.3334],\n",
       "        [0.2703, 0.3458, 0.3839],\n",
       "        [0.3117, 0.3043, 0.3840],\n",
       "        [0.3411, 0.3668, 0.2921]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4bc52-c530-4fdb-9a0a-4e889597dbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
